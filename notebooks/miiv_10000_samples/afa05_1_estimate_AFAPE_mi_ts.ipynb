{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767b7864-b3cf-4539-8227-c6de2ef7c792",
   "metadata": {},
   "source": [
    "# (5.1) Solve AFAPE for dataset completed with multiple imputation\n",
    "Use an estimator to evaluate E[C|do(R_bar = 1)]. Also give valid confidence intervals (through estimating mean and variance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b810b65-dcaa-4ad0-b0ed-cf3737fd8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96136052-0cbe-41a9-a69f-5e2de963a509",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a07dc-1698-417c-9d75-a8d6323ca320",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44057c6d-6463-4519-804d-df2c37279cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_ts import specify_default_paths_ts\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_4_0\"\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) \n",
    "paths = specify_default_paths_ts(dataset_name = dataset_name , miss_scenario = miss_scenario) \n",
    "\n",
    "# name for agent \n",
    "agent_name            = 'DQN'\n",
    "agent_name            = 'Random 0% with TCN'\n",
    "\n",
    "agent_dir = paths['data_dir'] + 'afa_agents' + '/' + agent_name + '/'\n",
    "\n",
    "# how to name the afa_dataset\n",
    "mi_model_name   =  'mi_simple'\n",
    "mi_model_dir  =  paths['data_dir'] + 'mi_models/' + mi_model_name + '/'\n",
    "afa_dataset_name = mi_model_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04782040-9ef5-43e6-99b3-fc997fe88a62",
   "metadata": {},
   "source": [
    "## Load afa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d62da-8b4f-48e7-9f39-a635a95b65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 12:32:38.197983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 12:32:38.354816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:38.354836: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-11 12:32:39.069837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:39.069948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:39.069957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_ts import DataLoader_ts\n",
    "from afa.data_modelling.missingness.multiple_imputation.multiple_imputed_data_loader.multiple_imputed_data_loader_ts import MultipleImputedDataLoader_ts\n",
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_ts import AFADataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d3a81d-4bdf-4286-9645-097cee851433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2106.41it/s]\n",
      "Padding sequences: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2019.49it/s]\n",
      "Padding sequences: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1767.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "data_loader = DataLoader_ts(     data_file                  = paths['data_file'],\n",
    "                                 temporal_data_file         = paths['temporal_data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'],\n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34c5fa1-0839-445a-b90a-5f9cc98cff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mi dataset\n",
    "augmented_data_file = mi_model_dir + 'results.hkl'\n",
    "mi_model_params = None\n",
    "mi_data_loader = MultipleImputedDataLoader_ts(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = dataset,\n",
    "                    model_params        = mi_model_params) \n",
    "mi_dataset = mi_data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30095f1f-6dd1-4950-a8dc-8686604c882d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'target_feature'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_dataset.results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5067e4d-de37-4fd6-8799-e783ad4792d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 12:32:50.104957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-11 12:32:50.105302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:50.105395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:50.105465: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:50.105524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-11 12:32:50.105578: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-11 12:32:50.105966: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load afa_dataset\n",
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_agent_params = None\n",
    "afa_data_loader = AFADataLoader_ts(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = mi_dataset,\n",
    "                    model_params        = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773a2eea-f79a-4f37-b18a-390f2103ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'target_superR_hat', 'label_pred', 'cost_acq', 'cost_mc', 'cost', 'mi_number'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, results = afa_dataset.get_augmented_data()\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402384f1-338a-4216-9800-8f17c0a12890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.86501492, -0.60501799, -0.0148572 ,  0.01026182],\n",
       "        [-0.04280796, -0.12856489, -0.43601789, -1.14884891],\n",
       "        [-0.53436443,  1.22542717, -0.78219913, -0.03030623],\n",
       "        [-0.6894841 , -0.54329778, -0.81760127,  0.81351747],\n",
       "        [-0.50308986,  0.66748985, -0.71051529, -0.641935  ]],\n",
       "\n",
       "       [[ 1.86501492, -0.60501799, -0.0148572 ,  0.01026182],\n",
       "        [-0.04280796, -0.12856489, -0.43601789, -1.14884891],\n",
       "        [-0.53436443,  1.22542717, -0.78219913, -0.03030623],\n",
       "        [-0.6894841 , -0.54329778, -0.81760127,  0.81351747],\n",
       "        [-0.50308986,  0.66748985, -0.71051529, -0.641935  ]],\n",
       "\n",
       "       [[ 1.86501492, -0.60501799, -0.0148572 ,  0.01026182],\n",
       "        [-0.04280796, -0.12856489, -0.43601789, -1.14884891],\n",
       "        [-0.53436443,  1.22542717, -0.78219913, -0.03030623],\n",
       "        [-0.6894841 , -0.54329778, -0.81760127,  0.81351747],\n",
       "        [-0.50308986,  0.66748985, -0.71051529, -0.641935  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.34686034,  0.89982627, -0.50553155,  1.77935754],\n",
       "        [ 0.88990133, -0.58539024, -0.45094813,  1.11445422],\n",
       "        [ 0.62344398, -0.22735214, -0.0148572 ,  0.01026182],\n",
       "        [-0.60384406,  0.39268246, -0.30489251, -0.94036318],\n",
       "        [-0.03053365, -0.12856489, -1.03303384,  0.37313125]],\n",
       "\n",
       "       [[ 0.34686034,  0.89982627, -0.50553155,  1.77935754],\n",
       "        [ 0.88990133, -0.58539024, -0.45094813,  1.11445422],\n",
       "        [ 0.62344398, -0.22735214, -0.0148572 ,  0.01026182],\n",
       "        [-0.60384406,  0.39268246, -0.30489251, -0.94036318],\n",
       "        [-0.03053365, -0.12856489, -1.03303384,  0.37313125]],\n",
       "\n",
       "       [[ 0.34686034,  0.89982627, -0.50553155,  1.77935754],\n",
       "        [ 0.88990133, -0.58539024, -0.45094813,  1.11445422],\n",
       "        [ 0.62344398, -0.22735214, -0.0148572 ,  0.01026182],\n",
       "        [-0.60384406,  0.39268246, -0.30489251, -0.94036318],\n",
       "        [-0.03053365, -0.12856489, -1.03303384,  0.37313125]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['temporal_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea2b65b-f145-483c-844d-a945157e4a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['cost_mc'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c599147-ed2f-43a3-bba9-6d64167aa075",
   "metadata": {},
   "source": [
    "## Compute estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388127c-1e11-4b50-86b5-3b68ac93baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_bootstraps = afa_dataset.estimate_counterfactual_cost_mi(  mi_model_name  = mi_model_name , \n",
    "                                                             fold = 0, split = \"test\", \n",
    "                                                             n_samples = None, \n",
    "                                                             n_bootstraps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44b918-5f45-41a3-9fff-00c1f24b49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimate\n",
    "from afa.afa_models.afa_estimators.utils import save_results_bootstrapping\n",
    "save_results_bootstrapping( J_bootstraps , agent_dir, afa_dataset_name = afa_dataset_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc95716-113e-4d5f-b86f-d268be5af299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f903ef5b-a358-4c83-91e5-6b6a3bd65d25",
   "metadata": {},
   "source": [
    "## Compute estimates for convergence\n",
    "If we know the ground truth, we might be interesting in plotting convergence, for this we might want to compute estimates J for different amount of available datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62750c70-9f2b-422c-a7ac-494b40ce21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_estimators.utils_ts import define_afa_estimator_ts\n",
    "from afa.afa_models.afa_estimators.utils import compute_counterfactual_cost_convergence_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a0b65-efd2-400d-8555-d7bbbb37f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init estiamtor \n",
    "estimators = [define_afa_estimator_ts(    estimator_name   = mi_model_name ,\n",
    "                                              estimator_type   = 'simple_blocking' ,\n",
    "                                              estimator_params = None) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168ea85-5048-41bf-9dea-91c709937860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimators \n",
    "J_bootstraps_convergence, convergence_steps  = compute_counterfactual_cost_convergence_mi(   afa_dataset = afa_dataset, \n",
    "                                                                                             mi_model_name = mi_model_name, \n",
    "                                                                                             fold = 0, split = \"test\", \n",
    "                                                                                             n_samples = 1, \n",
    "                                                                                             n_bootstraps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc17b4-437f-46f4-8033-8b0857b08af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimators\n",
    "save_results_bootstrapping( J_bootstraps_convergence , agent_dir, convergence_steps = convergence_steps, afa_dataset_name = afa_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162dbbc-c7ca-4df4-836c-97c5908d0231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16412c37-7b97-44f9-a23b-ff4797bf67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16cdb29-b320-440f-be38-6243324c7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca79821-f118-48e6-80c5-e7d315409319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
