{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b042bd6-b878-4c25-9564-0bb1cc59cc74",
   "metadata": {},
   "source": [
    "# (3.2) Create AFA dataset on ground truth dataset (no missingness) \n",
    "In this notebook we run the agent on a dataset without missingness. We save the created dataset.\n",
    "\n",
    "Note: AFA agents must be already trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b0575b-9c52-42a7-8a1d-4898c24a26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e750ac-9a3c-431c-8c52-61050ddd3c6e",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be4084-a54f-43c1-8f3b-617a7c2a10c6",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada6d072-bc28-40bb-baf4-9889074de048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_ts import specify_default_paths_ts\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_2\"\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) (WATCH OUT: LOAD ORIGINAL DATASET) \n",
    "paths = specify_default_paths_ts(dataset_name = dataset_name , miss_scenario = None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34e8a8-794c-48ee-967b-c598e59d9e00",
   "metadata": {},
   "source": [
    "Paths for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6d182c-34b5-4f57-8951-c09a86e2c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for agent (and predictor) \n",
    "agent_name            = 'DQN'\n",
    "predictor_model_name  = 'logistic_regression'\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# new (where to save the model) \n",
    "data_dir_models = '../../../data/ts/' + dataset_name + '/' + miss_scenario + '/' # where are the models \n",
    "agent_dir           = data_dir_models  + 'afa_agents' + '/' + agent_name + '/'\n",
    "predictor_model_dir = data_dir_models  + 'predictor_models' + '/' + predictor_model_name + '/'\n",
    "\n",
    "# how to name the afa_dataset\n",
    "afa_dataset_name = 'ground_truth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7902ec-4ce7-48f7-83f4-b4a29b727e16",
   "metadata": {},
   "source": [
    "## Load dataset with missingness \n",
    "At first, we want to load the dataset \n",
    "\n",
    "Includes loading: \n",
    "- superfeature mapping\n",
    "- problem\n",
    "- afa_problem \n",
    "- missingness_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758ec48b-0350-40fa-9561-7773fbdf6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 13:36:05.591249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 13:36:05.765805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-28 13:36:05.765827: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-28 13:36:06.763851: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-28 13:36:06.764093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-28 13:36:06.764114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_ts import DataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a400fb9-2940-40a2-9934-1693dcc77224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [01:07<00:00, 1479.98it/s]\n",
      "Padding sequences: 100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [00:55<00:00, 1805.05it/s]\n",
      "Padding sequences: 100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [00:57<00:00, 1743.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader_ts(     data_file                  = paths['data_file'],\n",
    "                                 temporal_data_file         = paths['temporal_data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5409476-fa22-4ca2-83ec-8f40464e2881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define predictor (has to be pretrained) \n",
    "predictor_model_params = {\n",
    "    'name' : predictor_model_name, \n",
    "    'directory': predictor_model_dir,\n",
    "    'base_model_params' : {   \n",
    "        'model_type': 'ImputeThenRegress',\n",
    "        'imputer_params' : {\n",
    "              'model_type': 'simple_imputer',\n",
    "              'mode' : 'imputation', \n",
    "            },\n",
    "        'predictor_params' : {\n",
    "              'model_type': 'ann',\n",
    "              'mode' : 'classification', \n",
    "              'units':              1,\n",
    "              'layers': 1,\n",
    "              'learning_rate': 0.01,\n",
    "              'batch_size' :128,\n",
    "              'epochs': 100\n",
    "          }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1c263-2372-45df-ad09-a5a1edf75d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agent\n",
    "agent_model_params =  {                       \n",
    "                    'num_iterations'              : 100,\n",
    "                    'initial_collect_steps'       : 50,\n",
    "                    'collect_steps_per_iteration' : 1, \n",
    "                    'replay_buffer_max_length'    : 100000 ,\n",
    "                    'batch_size'                  : 64,\n",
    "                    'learning_rate'               : 1e-3,\n",
    "                    'train_steps_per_iteration'   : 1, \n",
    "                    'log_interval'                : 200,\n",
    "                    'num_eval_episodes'           : 50,\n",
    "                    'eval_interval'               : 500, \n",
    "                    'verbose'                     : False\n",
    "                      }               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171b8c9-4939-4516-b5bf-e3deebf775a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define afa_agent\n",
    "afa_agent_params = {\n",
    "    'name' : agent_name,\n",
    "    'agent_type' : 'dqn_agent',\n",
    "    'directory' : agent_dir, \n",
    "    'predictor_params' : predictor_model_params, \n",
    "    'agent_params' : agent_model_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b7cf2-1e7a-4656-bf88-fbfe74cdcc40",
   "metadata": {},
   "source": [
    "## Initialize Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe0755-dd54-4d7f-97db-8f158b03ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_agents.utils_ts import define_afa_agent_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1ef8d-c27e-4222-a961-14298cc11389",
   "metadata": {},
   "outputs": [],
   "source": [
    "afa_agent = define_afa_agent_ts(         name             = afa_agent_params['name'],  \n",
    "                                         agent_type       = afa_agent_params['agent_type'],   \n",
    "                                         afa_agent_params = afa_agent_params ,\n",
    "                                         agent_directory  = afa_agent_params['directory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d4a32-5488-47e1-98f6-0832a40504c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create afa dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adae7e-056c-42f9-a72c-b79442dfaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.afa_dataset_ts import AFADataset_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006e98b-0c45-4bf5-a3d7-39e3f9d4b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "afa_results = afa_agent.predict(dataset,  n_samples = 1) \n",
    "\n",
    "# create an afa_dataset out of the generated afa_results\n",
    "afa_dataset = AFADataset_ts(  dataset = dataset, model = afa_agent, results = afa_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8fb60-35a8-4007-b247-b68810d4201c",
   "metadata": {},
   "source": [
    "### Run test for consistency check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf493f-7948-4827-8db6-306084a7650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.testing.test_afa_dataset_ts import test_afa_dataset_ts\n",
    "test_afa_dataset_ts(afa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd7c49-2363-494b-ba2e-b4fc487506b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save afa_dataset\n",
    "afa_dataset.save( directory = agent_dir, afa_dataset_name = afa_dataset_name ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a4b1f-5f1c-4f39-b922-4f9fcdd5b9de",
   "metadata": {},
   "source": [
    "## Test loading afa dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4164b9-5814-49c7-b15b-061145034588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_ts import AFADataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867967f7-6b0d-45e1-a4e6-d738c48aab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_data_loader = AFADataLoader_ts(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset  = dataset,\n",
    "                    model_params = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f140430-9a4b-40b8-8ae0-0673ca303448",
   "metadata": {},
   "outputs": [],
   "source": [
    "afa_dataset.results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc18b9-917c-4317-a492-fd3bfb48da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = afa_dataset.get_data(fold = None, split = None, n_samples = 1) \n",
    "# data = afa_dataset.get_data(fold = 0, split = 'val', n_samples = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4008eea-4490-42a2-9be9-24ad663fed15",
   "metadata": {},
   "source": [
    "### Write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc9756-e73b-45e1-a76c-1101aa41b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report \n",
    "explanation_file = agent_dir + afa_dataset_name + '_' + 'afa_dataset_report.md'  # +  'reports/' + 'model_report' \n",
    "afa_dataset.explain(file= explanation_file, format = 'markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf1200-d25d-47b0-8c4c-bc9b341a1f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
