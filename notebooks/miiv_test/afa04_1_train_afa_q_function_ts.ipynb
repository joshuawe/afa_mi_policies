{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b042bd6-b878-4c25-9564-0bb1cc59cc74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (4.1) Train a state-action value function (Q-function) on an AFA dataset\n",
    "In this notebook we train a Q-function that estimates the expected cost to go if we were in a fully observed environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b0575b-9c52-42a7-8a1d-4898c24a26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e750ac-9a3c-431c-8c52-61050ddd3c6e",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be4084-a54f-43c1-8f3b-617a7c2a10c6",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada6d072-bc28-40bb-baf4-9889074de048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_ts import specify_default_paths_ts\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_1\"\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) \n",
    "paths = specify_default_paths_ts(dataset_name = dataset_name , miss_scenario = miss_scenario) \n",
    "\n",
    "# name for agent \n",
    "agent_name            = 'DQN' #'Random 10%' # 'DQN' #'Random 10%' # 'DQN' ##'Random 10%'\n",
    "agent_dir = paths['data_dir'] + 'afa_agents' + '/' + agent_name + '/'\n",
    "\n",
    "# how to name the afa_dataset\n",
    "afa_dataset_name = 'blocking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632f30d6-252e-43ad-9be4-ccc42d953292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for predictor \n",
    "q_model_name  = 'q_model' #'logistic_regression'\n",
    "\n",
    "# new (where to save the model) \n",
    "q_model_dir = paths['data_dir'] + 'q_models' + '/' + q_model_name + '/'\n",
    "\n",
    "# reporting\n",
    "explanation_file = q_model_dir +  'reports/' + 'model_report' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f674d-3ae1-4caf-ad0b-8bb968796129",
   "metadata": {},
   "source": [
    "## Load afa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c33fae-8482-46a3-a492-81594fe33a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_ts import DataLoader_ts\n",
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_ts import AFADataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5b718e-9655-434f-b722-a440198775a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1160.29it/s]\n",
      "Padding sequences: 100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1266.74it/s]\n",
      "Padding sequences: 100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1213.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "data_loader = DataLoader_ts(     data_file                  = paths['data_file'],\n",
    "                                 temporal_data_file         = paths['temporal_data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 miss_model_files           = paths['miss_model_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02fa135-e5f8-4046-8aa9-94533d830e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 16:42:19.783182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-27 16:42:19.783620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-27 16:42:19.783759: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-27 16:42:19.783863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-27 16:42:19.783960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-27 16:42:19.784043: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-27 16:42:19.784490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load afa_dataset\n",
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_agent_params = None\n",
    "afa_data_loader = AFADataLoader_ts(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = dataset,\n",
    "                    model_params        = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b7cf2-1e7a-4656-bf88-fbfe74cdcc40",
   "metadata": {},
   "source": [
    "## Initialize Q function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfe0755-dd54-4d7f-97db-8f158b03ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_nuisance_models.afa_q_models.afa_q_model_ts import AFAQModel_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6329a0b8-b0c5-455a-96e7-1f51f0e4b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model_params = {\n",
    "    'name' : q_model_name, \n",
    "    'directory': q_model_dir,\n",
    "    'base_model_params' : {   \n",
    "        'hidden_size': 16,\n",
    "        'epochs' :   10,\n",
    "        'batch_size' : 32\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9d6b6a5-4f16-476c-880b-ed1fa338ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "afa_q_model = AFAQModel_ts( name            = q_model_params['name'], \n",
    "                            model_params    = q_model_params, \n",
    "                            afa_dataset     = afa_dataset, \n",
    "                            directory       = q_model_params['directory'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb1ef8d-c27e-4222-a961-14298cc11389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert superR to R: 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2529.74it/s]\n",
      "Train Q-function: 100%|█████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.32it/s]\n",
      "Convert superR to R: 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1657.50it/s]\n"
     ]
    }
   ],
   "source": [
    "afa_q_model.fit(  afa_dataset, \n",
    "                  fold = 0, \n",
    "                  train_split = 'train_afa_nuisance', \n",
    "                  valid_split = 'test', \n",
    "                  fit_again = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe96c67-10e9-465b-9add-863a9aa799ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert superR to R: 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 4796.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_models/afa_nuisance_models/afa_nuisance_dataset_ts.py\u001b[0m(82)\u001b[0;36mcompute_afa_trajectories\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     80 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     81 \u001b[0;31m        \u001b[0;31m# fill feature_ordered with the acquired features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 82 \u001b[0;31m        \u001b[0mtarget_temporal_feature_acquired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_feature_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m        \u001b[0mtarget_temporal_feature_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtarget_R_hat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_models/afa_nuisance_models/afa_nuisance_dataset_ts.py\u001b[0m(83)\u001b[0;36mcompute_afa_trajectories\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     81 \u001b[0;31m        \u001b[0;31m# fill feature_ordered with the acquired features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m        \u001b[0mtarget_temporal_feature_acquired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_feature_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 83 \u001b[0;31m        \u001b[0mtarget_temporal_feature_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtarget_R_hat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_temporal_feature_acquired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-1.38872265, -0.37464611,  1.0090345 ],\n",
      "        [-0.38636235,  1.29420088, -0.18079483],\n",
      "        [-1.66834288,  1.19377219, -0.46709523],\n",
      "        [-1.06652083, -0.13601669,  0.1591873 ],\n",
      "        [ 0.2531797 , -0.18362632,  0.926272  ]],\n",
      "\n",
      "       [[ 0.1137695 ,  0.57393379, -0.12709364],\n",
      "        [-0.26760753,  0.22835893,  0.85295297],\n",
      "        [-1.06599963, -0.2256145 , -0.08851245],\n",
      "        [ 0.47434833,         nan,         nan],\n",
      "        [-0.58221457, -0.02412887,  0.53016757]],\n",
      "\n",
      "       [[-0.29713627,         nan,         nan],\n",
      "        [ 0.99672297, -1.52954639,  0.1291835 ],\n",
      "        [ 0.00502995, -0.04963145,  0.7019105 ],\n",
      "        [-1.27682788, -1.10937407,  0.38046483],\n",
      "        [        nan, -0.85908411,  0.24009836]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.45269892, -0.5074756 , -0.0347233 ],\n",
      "        [-0.53828857, -1.5893523 ,  0.0510782 ],\n",
      "        [-0.9836936 ,  0.04067825, -0.6014946 ],\n",
      "        [-0.14542348,  0.0747913 , -1.40108765],\n",
      "        [-0.59675417,  1.3119413 , -0.09357712]],\n",
      "\n",
      "       [[        nan, -0.44073886,  1.41166106],\n",
      "        [ 0.07984626, -0.22367308, -0.37402671],\n",
      "        [ 1.02189507,         nan,         nan],\n",
      "        [ 1.90420002, -0.26218122, -0.10431063],\n",
      "        [-1.80736051, -0.47723867, -0.00800249]],\n",
      "\n",
      "       [[ 1.25195215, -0.59851215, -0.41327365],\n",
      "        [ 1.19409694, -0.74864344, -0.43055991],\n",
      "        [-1.35462877,  1.27754704,  0.56114505],\n",
      "        [ 0.72983174,  0.14565531,  0.58118681],\n",
      "        [ 0.13242635,  0.1878305 , -0.31812829]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_temporal_feature_acquired.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_R_hat.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_R_bar = np.isnan(target_R_hat)\n",
      "ipdb>  target_R_bar .shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_R_bar \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]],\n",
      "\n",
      "       [[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar - target_R_hat).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar *1- target_R_hat*1).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar *1- target_R_hat*1).min()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_temporal_feature_acquired[~target_R_hat] = 0\n",
      "ipdb>  np.isnan(target_R_hat).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_temporal_feature_acquired = self.temporal_feature[:,:,self.target_feature_inds]\n",
      "ipdb>  target_temporal_feature_acquired[~target_R_hat] = 0\n",
      "ipdb>  np.isnan(target_temporal_feature_acquired).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  target_R_bar = np.isnan(self.temporal_feature)\n",
      "ipdb>  (target_R_bar - target_R_hat).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar *1- target_R_hat*1).min()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ValueError: operands could not be broadcast together with shapes (100,5,4) (100,5,3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar[:,:,self.target_feature_inds] *1- target_R_hat*1).min()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (target_R_bar[:,:,self.target_feature_inds] *1- target_R_hat*1).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.target_superR_hat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 1]],\n",
      "\n",
      "       [[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "q_values, v_values  = afa_q_model.predict(   afa_dataset, \n",
    "                                              fold = None, \n",
    "                                              split = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35970985-0f3f-4a18-b836-0fb5240ad3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to afa_dataset \n",
    "results = {}\n",
    "results['q_values_' + q_model_name] = q_values\n",
    "results['v_values_' + q_model_name] = v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc96057-79e7-4b8a-994a-32c20861f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "afa_dataset.set_augmented_data( \n",
    "                            results,\n",
    "                            set_nuisances = True, \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894f1a1f-724c-4529-965d-69fb144980de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q_values', 'actions', 'q_values_q_model', 'v_values_q_model'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afa_dataset.results['nuisances'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9e4708-5696-43ae-97b3-b1d48cc36eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q_values', 'actions', 'q_values_q_model', 'v_values_q_model'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, results_new = afa_dataset.get_augmented_data(get_nuisances = True)\n",
    "results_new['nuisances'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5561b-a2be-4486-b627-5b14da92588a",
   "metadata": {},
   "source": [
    "## Save afa_dataset with Q and V values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9afd7c49-2363-494b-ba2e-b4fc487506b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save afa_dataset\n",
    "afa_dataset.save( directory = agent_dir, afa_dataset_name = afa_dataset_name ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a4b1f-5f1c-4f39-b922-4f9fcdd5b9de",
   "metadata": {},
   "source": [
    "## Test loading afa dataset with Q and V values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a4164b9-5814-49c7-b15b-061145034588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_static import AFADataLoader_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867967f7-6b0d-45e1-a4e6-d738c48aab51",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m augmented_data_file \u001b[38;5;241m=\u001b[39m agent_dir \u001b[38;5;241m+\u001b[39m afa_dataset_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.hkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m afa_data_loader \u001b[38;5;241m=\u001b[39m AFADataLoader_static(                   \n\u001b[1;32m      3\u001b[0m                     augmented_data_file \u001b[38;5;241m=\u001b[39m augmented_data_file,\n\u001b[1;32m      4\u001b[0m                     dataset  \u001b[38;5;241m=\u001b[39m dataset,\n\u001b[1;32m      5\u001b[0m                     model_params \u001b[38;5;241m=\u001b[39m afa_agent_params) \n\u001b[0;32m----> 6\u001b[0m afa_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mafa_data_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/data_modelling/datasets/augmented_dataset/augmented_data_loader/augmented_data_loader.py:57\u001b[0m, in \u001b[0;36mAugmentedDataLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m augmented_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_augmented_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m augmented_dataset\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_data_loader/afa_data_loader_static.py:39\u001b[0m, in \u001b[0;36mAFADataLoader_static._init_augmented_dataset\u001b[0;34m(self, dataset, results, model)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_augmented_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, results, model):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Initialize the augmented dataset object \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     afa_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAFADataset_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m afa_dataset\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset_static.py:39\u001b[0m, in \u001b[0;36mAFADataset_static.__init__\u001b[0;34m(self, dataset, model, results)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, model, results):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset.py:42\u001b[0m, in \u001b[0;36mAFADataset.__init__\u001b[0;34m(self, dataset, model, results)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dataset \u001b[38;5;241m=\u001b[39m dataset, model \u001b[38;5;241m=\u001b[39m model, results \u001b[38;5;241m=\u001b[39m results )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# compute costs (and add to results)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# update afa propensity scores (i.e. compute some more nuisances)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# self._compute_afa_ps_values(ids = np.unique(results['ids']))\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# self._compute_afa_ps_values(   )\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset.py:234\u001b[0m, in \u001b[0;36mAFADataset._update_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_pred\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_pred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# compute costs \u001b[39;00m\n\u001b[1;32m    233\u001b[0m     results_cost \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 234\u001b[0m     results_cost[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_acq\u001b[39m\u001b[38;5;124m'\u001b[39m], results_cost[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_mc\u001b[39m\u001b[38;5;124m'\u001b[39m], results_cost[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# set the newly computed values (make sure they match with ids)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_augmented_data(    \n\u001b[1;32m    238\u001b[0m         new_results \u001b[38;5;241m=\u001b[39m results_cost,\n\u001b[1;32m    239\u001b[0m         set_nuisances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset.py:95\u001b[0m, in \u001b[0;36mAFADataset._compute_costs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mCompute the costs that are associated the results. Adds them to results.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    sum of misclassification costs per datapoint\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m cost_acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_acquisition_costs()\n\u001b[0;32m---> 95\u001b[0m cost_mc  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_mc_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     96\u001b[0m cost     \u001b[38;5;241m=\u001b[39m cost_acq \u001b[38;5;241m+\u001b[39m cost_mc\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  cost_acq, cost_mc, cost\n",
      "File \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset_static.py:167\u001b[0m, in \u001b[0;36mAFADataset_static._compute_mc_costs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# data        = self.dataset.get_data(ids = ids)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m label       \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \n\u001b[1;32m    165\u001b[0m cost_mc     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafa_problem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_misclassification_cost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m--> 167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m() \n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cost_mc\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_data_loader = AFADataLoader_static(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset  = dataset,\n",
    "                    model_params = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc18b9-917c-4317-a492-fd3bfb48da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, results_new = afa_dataset.get_augmented_data(get_nuisances = True)\n",
    "results_new['nuisances'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad623d-e793-4831-82a2-22ffe159a7e0",
   "metadata": {},
   "source": [
    "### Write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47fee7-a0dc-4adb-b30c-155cb8141e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report \n",
    "# explanation_file = q_model_dir + afa_dataset_name + '_' + 'q_values_report.md'  # +  'reports/' + 'model_report' \n",
    "# afa_dataset.explain(file= explanation_file, format = 'markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf30b5-bc65-433d-9ff3-37b67c8618ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
