{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c30e44e-52d6-4634-b522-c267d9d25c18",
   "metadata": {},
   "source": [
    "# (1) Train predicator (classifier) for AFA \n",
    "The AFA problem contains the training of a classifier that is able to predict well based on any acquired subset of features. \n",
    "In this notebook we train and save such a classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef781ed-4103-4ab3-9f58-0839da5b5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57977939-d5d3-4f0c-bd02-170beb177566",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01ecb4-228b-4953-bca7-390eeeb74aa7",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48c5748-725f-4cc6-80b9-908f1b32664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_ts import specify_default_paths_ts\n",
    "# which dataset to work on \n",
    "dataset_name   = \"miiv_test\"\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) \n",
    "paths = specify_default_paths_ts(dataset_name = dataset_name , miss_scenario = miss_scenario) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f309b-441c-4c0b-a6d8-89837df5a91f",
   "metadata": {},
   "source": [
    "Paths for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28e2e44-576f-4371-9ab8-001a0ab989e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for predictor \n",
    "predictor_model_name  = 'TCN'\n",
    "\n",
    "# new (where to save the model) \n",
    "predictor_model_dir = paths['data_dir'] + 'predictor_models' + '/' + predictor_model_name + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26bb79-a599-4ec2-8714-395774f29e86",
   "metadata": {},
   "source": [
    "## Load dataset with missingness \n",
    "At first, we want to load the dataset \n",
    "\n",
    "Includes loading: \n",
    "- superfeature mapping\n",
    "- problem\n",
    "- afa_problem \n",
    "- missingness_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e389e952-73f7-4961-aaf3-7da80d5ebc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 16:02:06.585841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 16:02:06.701156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-07 16:02:06.701174: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-07 16:02:09.841973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-07 16:02:09.842052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-07 16:02:09.842059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_ts import DataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cd08c0-44c4-4f01-88d7-33ccd11bc28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|██████████| 100/100 [00:00<00:00, 2077.51it/s]\n",
      "Padding sequences: 100%|██████████| 100/100 [00:00<00:00, 2307.38it/s]\n",
      "Padding sequences: 100%|██████████| 100/100 [00:00<00:00, 1524.17it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader_ts(     data_file                  = paths['data_file'],\n",
    "                                 temporal_data_file         = paths['temporal_data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 miss_model_files           = paths['miss_model_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539523a-b1e7-4b8f-b010-3082ae3817ff",
   "metadata": {},
   "source": [
    "## Create afa dataset with missingness \n",
    "To train an AFA predictor, we need to induce artificial missingness (such that the predictor is robust to the missingness pattern). \n",
    "Here, we use a simple model to create missingness randomly (MCAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f443fefb-ebed-4e35-bd9a-3b10988dc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.utils_ts import create_MCAR_afa_dataset_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f3bc2c-8c2c-407b-9d28-b8779a262a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change base_model to stationary_constant\n",
      "Change base_model to stationary_constant\n",
      "Set weight for constant stationary model ...\n",
      "Set weight for constant stationary model ...\n"
     ]
    }
   ],
   "source": [
    "afa_dataset = create_MCAR_afa_dataset_ts( dataset, MCAR_ratio = 0.9, n_samples = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25e9b6-f18b-47fb-9240-58efb84201ca",
   "metadata": {},
   "source": [
    "## Train Predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea987f31-febe-4053-9b9e-10dca7a72cfd",
   "metadata": {},
   "source": [
    "### Initialize predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e3df59-098e-4ccb-a5ee-9ba6e9f0c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_predictors.afa_predictor_ts import AFAPredictor_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4921f92-6e4c-49df-803a-682423b8e0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_model_params = {\n",
    "    'name' : predictor_model_name, \n",
    "    'directory': predictor_model_dir,\n",
    "    'base_model_params' : {   'model_type': 'ImputeThenRegress',\n",
    "                              'imputer_params' : \n",
    "                                       {   \n",
    "                                      'model_type': 'simple_imputer',\n",
    "                                      'mode' : 'imputation'\n",
    "                                      },\n",
    "                              'predictor_params' : \n",
    "                                       {   \n",
    "                                      'model_type': 'ann',\n",
    "                                      'mode' : 'classification',\n",
    "                                      'units':              1,\n",
    "                                      'layers': 1,\n",
    "                                      'learning_rate': 0.01,\n",
    "                                      'batch_size' :128,\n",
    "                                      'epochs': 100 \n",
    "                                      }\n",
    "                          }\n",
    "    }\n",
    "\n",
    "predictor_model_params = {\n",
    "    'name' : predictor_model_name, \n",
    "    'directory': predictor_model_dir,\n",
    "    'base_model_params' : {   \n",
    "        'model_type': 'TCN',  \n",
    "        'seed': 54,                     # seed for reproduceability\n",
    "        'lr': 0.01,                     # initial learning rate for lr-scheduler\n",
    "        'time excluded': True,          # for logging purposes, if time is included as a feature\n",
    "        'num_inputs': 48,                # The number of features that are used as input\n",
    "        'num_layers': 2,                # The number of temporal conv. layers\n",
    "        'channels_per_layer': 8,        # The number of channels per temp. conv. layer\n",
    "        'kernel_size': 3,               # Num time steps for kernel window\n",
    "        'max_epochs': 100,              # Max. epochs for training\n",
    "        'batch_size': 2000,             # Number of samples per batch\n",
    "        'dropout': 0.1,                 # Dropout for all temp. conv. layers\n",
    "        'patience': 40,                 # Num epochs as patience for early stopping, default 50.\n",
    "        'weight_decay': 0,              # Weight decay for L2 regularization of Adam optmizer\n",
    "        'wandb_logger': False,           # If weights and biases logger should be used\n",
    "        #'wandb_project_name': 'Synthetic_2 classifier (AFA)'    # project name if wandb_logger is used\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "399aeb50-ea4b-4d63-985d-b241a332e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating the TCN_Lightning model...\n",
      "No previously trained model found.\n",
      "Conv1d layer initialized with Kaiming Uniform.\n",
      "MLP part input size:  8\n",
      "Value recognized as pad value: -1\n",
      "TCN_lightning(\n",
      "  (loss): MaskedBCEWithLogitsLoss()\n",
      "  (model): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): TemporalBlock(\n",
      "        (conv1): Conv1dWithWN(48, 8, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (conv2): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1dWithWN(48, 8, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(48, 8, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): TemporalBlock(\n",
      "        (conv1): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (conv2): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv1dWithWN(8, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Debug: Using Tensorboard logger.\n",
      "{'batch_size': 2000,\n",
      " 'channels_per_layer': 8,\n",
      " 'directory': '../../../data/ts/miiv_test/MCAR_1/predictor_models/TCN/',\n",
      " 'dropout': 0.1,\n",
      " 'kernel_size': 3,\n",
      " 'lr': 0.01,\n",
      " 'max_epochs': 100,\n",
      " 'model_type': 'TCN',\n",
      " 'num_channels': [8, 8],\n",
      " 'num_inputs': 48,\n",
      " 'num_layers': 2,\n",
      " 'patience': 40,\n",
      " 'seed': 54,\n",
      " 'time excluded': True,\n",
      " 'wandb_logger': False,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "afa_predictor = AFAPredictor_ts(    name            = predictor_model_params['name'], \n",
    "                                    model_params    = predictor_model_params, \n",
    "                                    directory       = predictor_model_params['directory'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b521049-ef7e-4b80-8a50-015475834a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert superR to R: 100%|██████████| 2/2 [00:00<00:00, 3240.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Global seed set to 54\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | loss  | MaskedBCEWithLogitsLoss | 0     \n",
      "1 | model | TemporalConvNet         | 2.2 K \n",
      "2 | fc    | Sequential              | 9     \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch.shape:  torch.Size([26, 120, 49])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123250c858a34a63a63f8e4bcae9dba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877bb2fe5c2a44ab9ed62300974e361e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2090d8d1f3414eb74e13e1e5311c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss = nan is not finite. Previous best value was inf. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Careful, using val_dataloader for final metrics. Please use test_dataloader if you have one.\n",
      "Applying sigmoid to y_pred!\n",
      "(1680,) (1680,) (1680,) (1680,)\n",
      "y_true: (1680,), y_logits: (1680,), y_score: (1680,), y_pred: (1680,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m afa_predictor\u001b[39m.\u001b[39;49mfit(afa_dataset, \n\u001b[1;32m      2\u001b[0m                   fold \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m                   train_split \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m                   valid_split \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      5\u001b[0m                   fit_again \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa/afa_models/afa_predictors/afa_predictor_ts.py:57\u001b[0m, in \u001b[0;36mAFAPredictor_ts.fit\u001b[0;34m(self, afa_dataset, fold, train_split, valid_split, n_samples, fit_again)\u001b[0m\n\u001b[1;32m     55\u001b[0m data_train       \u001b[39m=\u001b[39m afa_dataset\u001b[39m.\u001b[39mget_data(fold \u001b[39m=\u001b[39m fold, split \u001b[39m=\u001b[39m train_split, n_samples \u001b[39m=\u001b[39m n_samples)\n\u001b[1;32m     56\u001b[0m X_train, y_train, t_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess( data_train )\n\u001b[0;32m---> 57\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model\u001b[39m.\u001b[39;49mfit(X_train,y_train, t \u001b[39m=\u001b[39;49m t_train, fit_again \u001b[39m=\u001b[39;49m fit_again) \n\u001b[1;32m     59\u001b[0m \u001b[39m# validation set\u001b[39;00m\n\u001b[1;32m     60\u001b[0m data_valid       \u001b[39m=\u001b[39m afa_dataset\u001b[39m.\u001b[39mget_data(fold \u001b[39m=\u001b[39m fold, split \u001b[39m=\u001b[39m valid_split, n_samples \u001b[39m=\u001b[39m n_samples)\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa/data_modelling/models/temporal_models/predictors/TCN/TCN_afa.py:222\u001b[0m, in \u001b[0;36mTCN_afa.fit\u001b[0;34m(self, X, y, t, fit_again)\u001b[0m\n\u001b[1;32m    185\u001b[0m torch\u001b[39m.\u001b[39mset_float32_matmul_precision(\u001b[39m'\u001b[39m\u001b[39mmedium\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39m# # logging\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# if utils.is_wandb_available() and config.get('wandb', False):\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m#     project_name = config.get('wandb_project_name', 'TCN default')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \n\u001b[1;32m    221\u001b[0m \u001b[39m# Fit the model, yeah!\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    223\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \n\u001b[1;32m    224\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mdataloader_train, \n\u001b[1;32m    225\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mdataloader_val)\n\u001b[1;32m    227\u001b[0m \u001b[39m# Finalize logging for wand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m utils\u001b[39m.\u001b[39mis_wandb_available() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwandb_logger\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1122\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n\u001b[0;32m-> 1122\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_callback_hooks(\u001b[39m\"\u001b[39;49m\u001b[39mon_fit_end\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mon_fit_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1125\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: calling teardown hooks\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1394\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[1;32m   1393\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1394\u001b[0m             fn(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[1;32m   1397\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa/data_modelling/models/temporal_models/predictors/TCN/metrics.py:278\u001b[0m, in \u001b[0;36mFinalMetricsCallback.on_fit_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    274\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m    276\u001b[0m \u001b[39m# get fpr and tpr\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m# fpr, tpr, thresholds = roc_curve(y_true, y_score)\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m fig_roc, roc_auc \u001b[39m=\u001b[39m plot_roc_curve(y_true, y_score)\n\u001b[1;32m    279\u001b[0m fig_roc\u001b[39m.\u001b[39msavefig(save_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mroc.pdf\u001b[39m\u001b[39m'\u001b[39m, bbox_inches\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[39m# get AUROC\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m# confusion matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa/data_modelling/models/temporal_models/predictors/TCN/metrics.py:209\u001b[0m, in \u001b[0;36mplot_roc_curve\u001b[0;34m(y_true, y_score, figsize)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_roc_curve\u001b[39m(y_true: torch\u001b[39m.\u001b[39mTensor, y_score: torch\u001b[39m.\u001b[39mTensor, figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m)):\n\u001b[0;32m--> 209\u001b[0m     fpr, tpr, thresholds \u001b[39m=\u001b[39m roc_curve(y_true, y_score)\n\u001b[1;32m    210\u001b[0m     roc_auc \u001b[39m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m    211\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:747\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calculate true and false positives per binary classification threshold.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \n\u001b[1;32m    715\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39m    Decreasing score values.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39m# Check to make sure y_true is valid\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/sklearn/utils/multiclass.py:358\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    356\u001b[0m     data \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\n\u001b[1;32m    357\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39many(data \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)):\n\u001b[0;32m--> 358\u001b[0m         _assert_all_finite(data, input_name\u001b[39m=\u001b[39;49minput_name)\n\u001b[1;32m    359\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m    361\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/afa_ts/afa_env/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "afa_predictor.fit(afa_dataset, \n",
    "                  fold = 0, \n",
    "                  train_split = 'train', \n",
    "                  valid_split = 'val', \n",
    "                  fit_again = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df65e1c-7a7b-472f-9234-8e4e0b075e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert superR to R: 100%|██████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2932.05it/s]\n"
     ]
    }
   ],
   "source": [
    "label_pred = afa_predictor.predict( afa_dataset, fold = 0, split = 'val', n_samples = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54ad5d-82f9-492d-b2ff-f91e4047aee3",
   "metadata": {},
   "source": [
    "### Write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7bfd91-a0d0-45c7-b95a-182c528d3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_file = afa_predictor.directory + 'model_report.md'  # +  'reports/' + 'model_report' \n",
    "afa_predictor.explain(file= explanation_file, format = 'markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649d771-b660-4218-9327-2166d2b3417f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
